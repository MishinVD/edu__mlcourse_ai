{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20ff96c2-6e8f-474a-86a5-b762b7876b1c",
    "_uuid": "3cc7d9de4da8f868d983ec69b37546c51d68f407"
   },
   "source": [
    "Here we use a simple linear model and article content with `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10375e63-c7e4-4384-9521-1c5f20906eae",
    "_uuid": "889e971a7c32a4ac1dbc4ef55df672ab0f1ac9be"
   },
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "475f15a1-214d-4b48-b315-cdfa71c20c50",
    "_uuid": "7e5b949eafbf62826c6f02c39fdb55178d66fabd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2c1f42b4-423a-4ea6-a3a8-e783d1e10fda",
    "_uuid": "cf2daf1d4628d1f996e5c6180d3ee49bdbc8488f"
   },
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "37ad2332-3111-4983-a6aa-0961aeb6ae02",
    "_uuid": "e64bf63dbe42583a5080d31e19d7d283a6bc0c68",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "9051d077-6739-4fe2-83a5-6628f4833cbf",
    "_uuid": "dfeac755772fd66636d84221a80501754fe3dfbf",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_DATA = '../../../data/2019-03_ass02-2/'\n",
    "os.path.isdir(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60c7c92c-c387-4c1a-b272-fc36f85b0cef",
    "_uuid": "af961104abccccf1dff5638b7e97c474f56e51b8"
   },
   "source": [
    "Assume you have all data downloaded from competition's [page](https://www.kaggle.com/c/how-good-is-your-medium-article/data) in the PATH_TO_DATA folder and `.gz` files are ungzipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b6b85182-8ca8-4144-91ef-ceb472ce2518",
    "_uuid": "75ca681a11b040c9f5b3b38e37a9f99351ecf278",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3837900\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚     884217 Mar  9 21:09 sample_submission.csv\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚ 1156020029 Sep 20 09:56 test.json\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚  240600924 Mar  9 21:11 test.json.zip\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚          0 Mar  9 21:17 test_author.txt\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚          0 Mar  9 21:17 test_content.txt\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚          0 Mar  9 21:17 test_published.txt\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚          0 Mar  9 21:17 test_title.txt\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚ 2086185062 Sep 20 09:56 train.json\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚  445395631 Mar  9 21:13 train.json.zip\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚          0 Mar  9 21:25 train_author.txt\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚          0 Mar  9 21:25 train_content.txt\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚     912544 Mar  9 21:08 train_log1p_recommends.csv\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚          0 Mar  9 21:25 train_published.txt\n",
      "-rwxrwx---+ 1 User9 РћС‚СЃСѓС‚СЃС‚РІСѓРµС‚          0 Mar  9 21:25 train_title.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -l $PATH_TO_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8aa113b4-f062-46c2-ac90-c859a064226d",
    "_uuid": "5da5e0f993dc5bbd06d291c3fc1953aba470546e"
   },
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "badfb2bc-1f36-4311-a6aa-6452380e7e40",
    "_uuid": "bc1b8f0ecfba589b0714b9014fac3329793a2421",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4b78878e-b4f2-4a45-8be3-f789b3c3f221",
    "_uuid": "8ae68965cee9dfb58f88370e6a079ec4b2306e10"
   },
   "source": [
    "This function takes a JSON and forms a txt file leaving only article content. When you resort to feature engineering and extract various features from articles, a good idea is to modify this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "324441ce-e666-44c4-838c-acd78f9bfcf5",
    "_uuid": "e0fe7f2fd52b8f91c95cfb78c2af9d8e520cdd60",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(path_to_inp_json_file):\n",
    "    output_list = []\n",
    "    with open(path_to_inp_json_file, encoding='utf-8') as inp_file:\n",
    "        for line in tqdm_notebook(inp_file):\n",
    "            json_data = read_json_line(line)\n",
    "            content = json_data['content'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            content_no_html_tags = strip_tags(content)\n",
    "            output_list.append(content_no_html_tags)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "e901af5c-6623-449e-bce1-6e274022460e",
    "_uuid": "589761bb5972c78dee2694e08d3b94d6666e2bb6",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 9min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_raw_content = preprocess(path_to_inp_json_file=os.path.join(PATH_TO_DATA, \n",
    "                                                                  'train.json'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MediumEveryone’s stories and ideasAug 13, 2012Medium Terms of\\xa0ServiceEffective: March 7, 2016These Terms of Service (“Terms”) are a contract between you and A Medium Corporation. They govern your use of Medium’s sites, services, mobile apps, products, and content (“Services”).By using Medium, you agree to these Terms. If you don’t agree to any of the Terms, you can’t use Medium.We can change these Terms at any time. We keep a historical record of all changes to our Terms on GitHub. If a change is material, we’ll let you know before they take effect. By using Medium on or after that effective date, you agree to the new Terms. If you don’t agree to them, you should delete your account before they take effect, otherwise your use of the site and content will be subject to the new Terms.Content rights & responsibilitiesYou own the rights to the content you create and post on Medium.By posting content to Medium, you give us a nonexclusive license to publish it on Medium Services, including anything reasonably related to publishing it (like storing, displaying, reformatting, and distributing it). In consideration for Medium granting you access to and use of the Services, you agree that Medium may enable advertising on the Services, including in connection with the display of your content or other information. We may also use your content to promote Medium, including its products and content. We will never sell your content to third parties without your explicit permission.You’re responsible for the content you post. This means you assume all risks related to it, including someone else’s reliance on its accuracy, or claims relating to intellectual property or other legal rights.You’re welcome to post content on Medium that you’ve published elsewhere, as long as you have the rights you need to do so. By posting content to Medium, you represent that doing so doesn’t conflict with any other agreement you’ve made.By posting content you didn’t create to Medium, you are representing that you have the right to do so. For example, you are posting a work that’s in the public domain, used under license (including a free license, such as Creative Commons), or a fair use.We can remove any content you post for any reason.You can delete any of your posts, or your account, anytime. Processing the deletion may take a little time, but we’ll do it as quickly as possible. We may keep backup copies of your deleted post or account on our servers for up to 14 days after you delete it.Our content and\\xa0servicesWe reserve all rights in Medium’s look and feel. Some parts of Medium are licensed under third-party open source licenses. We also make some of our own code available under open source licenses. As for other parts of Medium, you may not copy or adapt any portion of our code or visual design elements (including logos) without express written permission from Medium unless otherwise permitted by law.You may not do, or try to do, the following: (1) access or tamper with non-public areas of the Services, our computer systems, or the systems of our technical providers; (2) access or search the Services by any means other than the currently available, published interfaces (e.g., APIs) that we provide; (3) forge any TCP/IP packet header or any part of the header information in any email or posting, or in any way use the Services to send altered, deceptive, or false source-identifying information; or (4) interfere with, or disrupt, the access of any user, host, or network, including sending a virus, overloading, flooding, spamming, mail-bombing the Services, or by scripting the creation of content or accounts in such a manner as to interfere with or create an undue burden on the Services.Crawling the Services is allowed if done in accordance with the provisions of our robots.txt file, but scraping the Services is prohibited.We may change, terminate, or restrict access to any aspect of the service, at any time, without notice.No childrenMedium is only for people 13 years old and over. By using Medium, you affirm that you are over 13. If we learn someone under 13 is using Medium, we’ll terminate their account.SecurityIf you find a security vulnerability on Medium, tell us. We have a bug bounty disclosure program.Incorporated rules and\\xa0policiesBy using the Services, you agree to let Medium collect and use information as detailed in our Privacy Policy. If you’re outside the United States, you consent to letting Medium transfer, store, and process your information (including your personal information and content) in and out of the United States.To enable a functioning community, we have Rules. To ensure usernames are distributed and used fairly, we have a Username Policy. Under our DMCA Policy, we’ll remove material after receiving a valid takedown notice. Under our Trademark Policy, we’ll investigate any use of another’s trademark and respond appropriately.By using Medium, you agree to follow these Rules and Policies. If you don’t, we may remove content, or suspend or delete your account.MiscellaneousDisclaimer of warranty. Medium provides the Services to you as is. You use them at your own risk and discretion. That means they don’t come with any warranty. None express, none implied. No implied warranty of merchantability, fitness for a particular purpose, availability, security, title or non-infringement.Limitation of Liability. Medium won’t be liable to you for any damages that arise from your using the Services. This includes if the Services are hacked or unavailable. This includes all types of damages (indirect, incidental, consequential, special or exemplary). And it includes all kinds of legal claims, such as breach of contract, breach of warranty, tort, or any other loss.No waiver. If Medium doesn’t exercise a particular right under these Terms, that doesn’t waive it.Severability. If any provision of these terms is found invalid by a court of competent jurisdiction, you agree that the court should try to give effect to the parties’ intentions as reflected in the provision and that other provisions of the Terms will remain in full effect.Choice of law and jurisdiction. These Terms are governed by California law, without reference to its conflict of laws provisions. You agree that any suit arising from the Services must take place in a court located in San Francisco, California.Entire agreement. These Terms (including any document incorporated by reference into them) are the whole agreement between Medium and you concerning the Services.Government use. If you’re \\u200busing \\u200bMedium for the U.S. Government, this Amendment to \\u200bMedium’s Terms of Service \\u200bapplies to you\\u200b.Questions? Let us know at legal@medium.com.Terms And ConditionsTermsMediumOne clap, two clap, three clap, forty?By clapping more or less, you can signal to us which stories really stand out.MediumMedium member since Aug 2017Everyone’s stories and ideasMedium PolicyThe Fine Print',\n",
       " 'MediumEveryone’s stories and ideasAug 2, 2015 UnlistedAmendment to Medium Terms of Service Applicable to U.S. Government UsersThis agreement (“Amendment”) is an amendment to Medium’s Terms. It is between Medium and the U.S. Government and applies to the use of Medium Services by the Government.The reason for this Amendment is that, as a U.S. Government entity (“you“ or “Agency”), you must follow federal laws and regulations when entering into a binding agreement such as Medium’s Terms. The subjects of these rules are broad and include ethics, privacy and security, accessibility, federal records, limitations on indemnification, fiscal law constraints, advertising and endorsements, freedom of information, and the details of how disputes are resolved.Medium and you (formally the “Parties”) have decided that modifications of Medium’s standard Terms, available at https://medium.com/policy/medium-terms-of-service-9db0094a1e0f, are appropriate to allow for federal-compatible usage of Medium Services. The changes are designed to respect your legal status, your public mission, and other unique circumstances. And so the Terms are modified by this Amendment, as follows.A. Government entity: We want to clear up what “you” means within the Terms. For Government users, “you” means the Agency itself and will not apply to nor bind the individuals who use Medium Services on the Agency’s behalf. Instead, Medium will look solely to the Agency to enforce any violation or breach of the Terms.B. Public purpose and usage: The Agency agrees to use Medium Services solely to fulfill the Agency’s public purpose. Medium acknowledges you may use Medium Services overseas and you may open and maintain more than one account. If Medium wants to promote your content with partner companies or services for broader broadcast, distribution, or publication, Medium will first contact you and make sure you understand and agree to Medium’s plans.C. Advertisements: Medium is allowed to serve what are commonly known as “house ads” on your pages in a non-intrusive manner. Medium does not currently display third-party advertisements, but this is subject to change. If you submit a written request to Medium to block the display of any commercial advertisements, solicitations, or links on the Agency’s board, Medium may so agree provided that it has decided to make such blocking technology generally available for all users. Agency’s sole remedy for Medium’s failure to implement such blocking technology shall be for Agency to terminate its Medium account.D. Indemnification, Liability, Statute of Limitations, Governing law and Forum: The title of this section looks complicated yet the proposition is simple. Medium agrees that any provisions in the Terms related to legal subjects\\u200a—\\u200asuch as indemnification, liability, damages, dispute forum, filing deadlines, defense of lawsuits, collection expenses, attorneys fees, and settlement\\u200a—\\u200awill apply to you only to the extent consistent with federal law. We expect everything to go smoothly, but Medium and you agree to proceed on the understanding that the Terms will be governed by and interpreted and enforced in accordance with applicable federal laws of the United States of America, and jurisdiction shall be in federal forums. To the extent permitted under federal law, the laws of the State of California will apply.E. Limitation of liability: The parties disclaim all warranties, express or implied, including any warranty of merchantability or fitness for a particular purpose. To the extent permitted under federal law, neither party will be liable to the other for indirect, consequential, special, punitive, or exemplary damages or penalties arising from or related to this agreement, and neither party’s liability for any cause of action arising from or relating to this agreement will exceed $50,000, except that we agree that nothing in the limitation of liability clause or elsewhere in the Terms in any way grants Medium a waiver from, release of, or limitation of liability pertaining to, any past, current or future violation of federal law.F. Access and use: Medium understands that the Agency’s use of Medium Services may energize significant citizen engagement and otherwise become important to your public mission. Medium agrees, before terminating your service, refusing or removing your content, or closing your account, to first notify you of Medium’s intent and to give you a reasonable opportunity to cure any identified breach or failure, or otherwise resolve the matter.G. No Endorsement: Agency’s trademarks, trade names, domain names, designs, logos and seals (“Agency Marks”), Agency’s name, and the fact that you have a presence on Medium Services, shall not be used to imply an endorsement, sponsorship or preference by Agency or the Federal Government of Medium Services. However, the foregoing shall not prohibit Medium from using your name or Agency Marks to fulfill Medium’s obligations under this agreement. Medium may also include the Agency’s name and Agency Marks in partner lists and presentations solely for the purpose of promoting the availability of Agency’s content on the Medium platform and only so long as the Agency name and Agency Marks are not displayed in a more prominent fashion than those of any other third party name or Mark. If you ever have concerns about or objections to our use of any Agency Mark, you may contact us (using the “Contact Us” feature in our developer portal) and we will discuss your concerns in good faith. You always have the ability to terminate your Medium account and, following any such withdrawal, we will stop using the applicable Agency Marks.H. No business relationship created: You and Medium are independent entities and nothing in the Terms as modified by this Amendment creates a partnership, joint venture, agency, or employer/employee relationship.I. No cost agreement: Nothing in the Terms as modified by this Amendment obligates you to expend appropriations or incur financial obligations. The Parties acknowledge and agree that none of the obligations arising from the Terms as modified by this Amendment are contingent upon the payment of fees by one party to the other.J. Paid Services and Agency responsibilities under paid usage plans: The Parties agree this Amendment applies to the Agency’s usage of both free and paid Services that Medium may offer. The Parties understand that fee-based products and services are categorically different than free products and services, and are subject to federal procurement rules and processes. Before the Agency decides to enter into a premium or enterprise subscription or any other fee-based service that Medium or alternative providers may offer now or in the future, the Agency agrees to determine if it has a need for those additional services for a fee, to consider the service’s value in comparison with comparable services available elsewhere, to determine that Agency funds are available for payment, to properly use the Government Purchase Card if it is used as the payment method, to review any then-applicable Terms for conformance to federal procurement law and in all other respects follow federal acquisition rules when making the acquisition.K. Assignment: Neither party may assign its obligations under the Terms as modified by this Amendment to any third party without prior written consent of the other. However, if you are using Medium’s free services only, Medium or its subsidiaries may, without your consent, assign the Terms as modified by this Amendment to an affiliate, successor or acquirer, as the case may be, in connection with a merger, acquisition, corporate reorganization or consolidation, or sale of all or substantially all of Medium’s assets.L. Termination rights: The Agency may close its account and terminate this agreement at any time. Medium may close the Agency’s account and terminate this agreement on 30 days written notice.M. Provision of data: In case of termination of service, within 30 days of such termination, upon request, Medium will provide you with all of your user-generated content that is publicly visible on the site. Data will be provided in a commonly used file or database format as Medium deems appropriate. Medium will not provide data if doing so would violate its privacy policy https://medium.com/policy/medium-privacy-policy-f03bf92035c9.N. Security: Security is important to Medium; please refer to our Terms of Service for information about our security practices. Recognizing the changing nature of the Web, Medium will continuously work with users to ensure that its site and Services meet users’ requirements for the security of systems and data. Medium agrees to discuss implementing additional security controls as deemed necessary by the Agency to conform to the Federal Information Security Management Act (FISMA), 44 U.S.C. 3541 et seq.O. Federal Records: The Agency acknowledges that use of Medium Services may require management of Federal records. If Medium holds Federal records, the Agency and Medium must discuss the proper care of Federal records in accordance with applicable records management laws and regulations, including the Federal Records Act (44 U.S.C. chs. 21, 29, 31, 33) and regulations of the National Archives and Records Administration (NARA; at 36 CFR Chapter XII Subchapter B). Managing the records includes, but is not limited to, secure storage, retrievability, and proper disposition of all Federal records including transfer of permanently valuable records to NARA in a format and manner acceptable to NARA at the time of transfer. The Agency is the party responsible for ensuring that its use of Medium is compliant with federal records management laws and regulations.P. Precedence; Further Amendments: If there is any conflict between this Amendment and the Terms, or between this Amendment and other terms, rules or policies on the Medium site or related to its Services, this Amendment shall prevail. Any further amendment must be agreed to in writing by both Parties. Current and future federal law, regulation and policy may affect the Agency’s use of Medium Services in ways not yet addressed by us. Among the topics the Agency may need to discuss with Medium, and which may lead to a mutual agreement to update this Amendment, are privacy and accessibility.Q. Posting of Amendment: This Amendment shall be posted with Medium’s online Terms either by incorporation of its text or via an integral link. Unlisted Public domain. One clap, two clap, three clap, forty?By clapping more or less, you can signal to us which stories really stand out.MediumMedium member since Aug 2017Everyone’s stories and ideasMedium PolicyThe Fine Print',\n",
       " \"Yun-Chen Chien（簡韻真）Nobody in @g0v.tw, PM in sense.tw to build online deliberation tools. Caring #civictech #opengov #startup. Now researching on Internet and open democracy.Feb 5, 2017走入山與海之間：閩東大刀會和兩岸走私閩東海濱是個山接海的地方，沿海是小小的灣澳錯落，漁船或遠或近地停泊。當我們沿著海邊走時，羅士傑老師總會興奮地說：「你看這地方，多適合躲人，就一副海盜窩的樣子！」這是一句激動的讚美，因為我們來此的目的是探訪民國時期的民間宗教武裝結社還有兩岸走私貿易。閩東沿岸的星星就是我們這次拜訪的地方。翻開閩東各地縣誌，從清末開始就充滿著各種倭寇進犯、禁烟令（禁止種植罌粟）、反洋教運動、取締花會捐（賭博）、緝鹽、民眾運動、走私。其中兩件事特別吸引了我們的注意。一是民國 32 年（1943 年）的大刀會暴動，聚集千餘人攻陷穆陽，國民黨政府緊急鎮壓，在民國 33 年處決首犯數餘人。大刀會是由地方仕紳組織成立的地方宗教團體「同善社」所延伸出來的武裝組織，目的是「防匪保家」。例如福安的同善社在民國 10 年創立於文昌祠樓上，民國 28 年反對當時縣長而暴動，有卸任知縣參與，被指控與「海匪」勾結，被指控以法師號召民眾、拜畸形兒做皇帝。後各地組織有與地方組織紅帶會結盟或對立，被國民黨肅清或接受國民黨資助對抗共產黨。這些所謂的「反動會道門」組織，一直在民間繼續傳佈，直到 1950-1960 年中國共產黨大力取締殲滅瑤池道、先天道、老母道、龍華道等「反動會道門」組織，才逐漸銷聲匿跡。二是綿延不斷的兩岸走私貿易。1950's - 1960's 兩岸仍不斷互相砲擊、飛偵測機、心戰喊話，甚至美軍和國民黨有空投昆蟲和細菌，縣誌上則記載陸續逮捕國民黨特務還有與海上保安隊對抗的紀錄。但有趣的是，在兩岸正式交流之前，1979 年三沙台灣漁民接待站就竣工了，1984 年後開始破獲走私，像是 1991 年霞浦破獲走私香菸三百多萬元，其他熱門走私品包括手錶、漁穫等。我們循著這兩條線索踏入閩東，展開歷史田野。身為歷史學家，老師有興趣的題目一直是「民間如何應對現代國家」，尤其以宗教作為地方組織的力量切入。如果單從檔案字面上看，我們很容易就對國家的敘事買單，但老師將民間視作有能動性的各種群體，有自己的邏輯，用自己的方法在跟所謂的「國家」互動。大概就是所謂的上有政策下有對策。這次文獻所引出的幾個有趣問題是，同善社、大刀會這樣的宗教紐帶，如何建立起地方武裝力量，他們又是如何與國民黨/中華民國、共產黨/中華人民共和國互動？同善社、大刀會這樣的宗教組織，也不若之前許多文獻中以廟宇為中心的討論地方的方法，而是以佛堂、法師為中心的組織。這樣的宗教組織，如何面對現代性的國家？尤其是當進入冷戰格局的兩岸對峙，對於地方脈絡來說，共產黨、國民黨、合法、非法的認知，還有國家對於他們來說又是什麼呢？宗教與地方三沙冬澳媽祖宮前老師上課總愛開玩笑說，在華南做宗教地方研究就是進村找廟、進廟找碑。這句話一半對。我們的確沿著舊時的海岸線，探訪了幾間天后宮、文武靈王廟，往外眺望曾經是海的地方。也在前岐的天后宮撒麵粉抄錄了奉憲示禁碑，從前岐這個明礬出口的河口，一路追到靠近溫州的明礬主要產地礬山鎮。（這是另外一個有意思的明礬貿易與「階級革命」的故事了，老師說應該可以寫一篇碩論了）但就像在字裡行間看出微言大義，我們在找官方敘事之外的民間故事還有廟宇之外的地方宗教運作方式。根據當時的調查文獻上，所謂的「反動會道門」有各式各樣職業，許多是城市小資產階級，不乏外地人，設壇於民宅中，由法師定時帶領會眾誦經行法事。老師解釋說宗教不只是逢年過節祭拜而已，需要形成團體互相支持。但在我看來這樣的組織是平行於媽祖信仰的、文武靈王、華光大帝的一種信仰方式，不然直接以媽祖做為號召即可，何必再搞出一個老母娘/瑤池金母在拜呢？地方上的宗教組織，可能是有好幾個宗教團體相互拮抗，像是如今的一貫道與媽祖信仰平行吸納群眾信仰。反動會道門在 1960’s 後基本上銷聲匿跡，這種祕密宗教組織也難以短時間與當地人聊天取得資訊。不過我們在三沙找到天地壇，裡面祭拜當年的壇主與不知名神明。也在天后宮裡發現兼拜奶娘。或是記述毛一、毛二法師行至羅源一帶弘法治病。在連江一帶則沿路多佛堂，有師父定時帶領誦經念課。其中一個佛堂裡的顧堂大嬸跟我們表示，這間佛堂本在偏僻山中，由「菜友」集資買下現在這塊地，興建佛堂，觀看廟牆上的捐獻紀錄多見女性，呼應文獻上鄉村中老年女性藉由宗教活動脫離家庭責任。拜觀音需脫鞋，旁邊則是一個食堂，有桌椅和廚房供集會之用。佛堂也更進一步與安養系統整合，我們進到一個直接名為「安養念佛堂」的佛堂，裡面有三十多位年長居士居住，兩三位師父，富麗堂皇。不過這樣的宗教組織聯繫，有沒有在兩岸之間牽起貿易網絡呢？這點還不是很清楚。或是宗教武裝組織如何與現代化互動？在文獻看起來，大刀會這批人先是被國民黨認為是迷信的地方組織需要清肅，後抗日又有合作，又與共產黨不合，國民黨在 1949 年撤退後還提供機關槍供其對抗共產黨。宗教在地方的形式會經過許多轉化與整合，例如這次拜訪的許多廟宇是在西元兩千年後才修建，可視為配合地方復興政策，或是那時鄉村真的開始富起來了，或是配合統戰政策，例如一間天后宮牆上貼著胡錦濤 2006 年 1 月時的談話：「媽祖信仰深深的紮根在台灣民眾的精神生活中，我們要運用好這一豐富資源，在促進兩岸交流中更好地發揮作用。」許多廟宇也與地方文化禮堂結合，一樓是挑高的禮堂活動空間，二樓則是廟。最絕的可能是我們走訪的一間鄭氏宗祠，上面掛了三個匾額：文化禮堂、鄭成功紀念館、鄭氏宗祠。看起來顯然是為了拿補助，一口氣讓整個場館多功能，一樓有球桌和很大的鄭成功塑像，二樓則是宗祠。這可視為地方對於政策的一種應對，以政策要求的外殼包裝地方需求。從大陸面對海洋：敵人還是朋友？「祖國大陸距離馬祖最近的地方」，大大的標語掛在連江縣黃岐鎮的入口。的確很近，1950 年馬祖駐軍砲擊黃岐鎮，三十多座民房被毀。如今在黃岐小三通的客運碼頭，寫著「連江縣同胞熱烈歡迎台灣同胞拜訪祖國大陸」，一天各兩班船班往返馬祖，航程不到三十分鐘。港口旁是頂著斗笠在補網的漁民，直接把網鋪開在馬路上，有羊在旁邊悠閒的晃蕩，不遠處則是船員介紹所。這裡講的方言屬福州系統，但在其他許多靠海的小漁村裡，雖靠近福州，我們竟可以以閩南語通行。老師一個想像是閩南語人群是海上的人，因此靠海的港口可能會有閩南語。閩東可能是最後一個蜑民上岸的地方。水上仍有人家我們跑了五天的沿海漁村，其實面貌各異。除了傳統的小漁村，有的地方建造海堤把河口內海做為農地，有的地方填海造建鋼鐵廠、核電廠或是一座每棟建築都二十層樓高且長的一模一樣的新城，也有些地方開一般的工廠，村裡的大街在辦年貨擠的水泄不通。也有些地方布滿的解放軍的軍事基地，商業化大概就無緣了。這也不奇怪，閩東歷來就有許多海防的衛所，我們拜訪了定海古城和浦城。衛所是明代的軍事制度，從外地派駐軍隊，駐紮在高牆圍起的城裡，佔據海防要地，依山傍海，山後有屯田。不過如今駐紮於此的解放軍，許多都是劃在南京軍區下的南方人，很多是福建人。我們跟身著藍色迷彩服的解放軍一同搭船前往三都澳，光緒二十三年正式開放作為對外通商口岸，設置海關。街上一片蕭索，我們氣喘吁吁爬上了一座山坡，俯瞰整個三都澳的港灣，山頭上座落著教堂還有貌似海關/洋行的歐式建築。我們跟一個在解放軍部隊待了十二年的大哥聊天，他說：「我恨死陳水扁了。我那時請假回家結婚，結果結婚前一天接到士官長的電話要我回部隊『戰備』，就只因為陳水扁要參選，還是長官給我方便，給我說成是去遼寧，趕回部隊要三天，我才結到婚的。但之後每次跟老婆吵架，她就會說：『我從結婚那天就看你很不順眼了！』」我啃著繼光餅（對，就是傳說戚繼光打倭寇時做的餅），聽老師跟大哥聊抓逃兵聊得不亦樂乎，原來兩岸抓逃兵的 SOP 和規定是一樣的啊！大哥說兩岸和平該有多好，大家都是可以交朋友嘛。說到走私，當地人說船體通體漆黑，沒有船舷，開得飛快，海防艦艇追不上。其中買賣油是筆好生意，台灣漁民會把油加滿開到公海上，大陸這頭的漁民再去取油，兩方心照不宣。沿途也有看到佔地甚廣的台灣漁民招待所。這些招待所建在兩岸正式通航之前。這些「漁民」在此之前可能被視作「特務」，從請吃子彈到請喝茶互相作為心戰宣傳管道。其實走私沒我們想像的那麼遠。從廈門小三通回台灣時，當地旅行社的櫃檯一直要我們「帶包香菇」，一個人給你一百元人民幣。當時直接拒絕了，很怕不是真的香菇，但上網查了之後發現好像是真的香菇，只是台灣跟中國的香菇價差太大了。雜記文章最後還是沒回答文章一開始針對宗教與走私所提出的大問題，只是用這樣的角度看民間社會與現代國家的互動會很有趣，就請大家期待老師的論文吧！這趟走下來，除了推論歷史，我不斷提醒自己的是要去看見那些互聯網之外的地方，尤其我們走在那些百度地圖上沒有的小路上時。羅士傑老師一向關注人是怎麼活著的，我則在思考當我們說著公民科技的時候，這樣的科技對於農村的人生活影響能有多少，有科技就能翻轉政治權力嗎？還是需整合舊有的民間凝聚力量？下一代的農村年輕人還會依附於宗教上嗎？他們信仰的會是什麼？老師回台灣的路上一直在講台灣人年輕人\\u200a—\\u200a尤其是要台獨的人\\u200a—\\u200a對中國不夠瞭解，不理解中國年輕人的話題也不瞭解農村。福建鄉下地方過年熱鬧的緊，鎮上那條大街整排的樹都掛上了紅燈籠，採買年貨的人穿梭在狂按喇吧的車陣中，幾個小孩蹦跳而過，老師轉身問我：「你覺得十年後這些小孩會在做什麼？」附錄感謝臺大歷史系羅士傑教授，以及台大歷史所學姐鄭凌霄，學姐正好是福州羅源人，一路上張羅田野行程還有方言翻譯。出田野有在地人真的很重要啊！福安縣誌 p697福安縣誌 p698福安縣誌 p733,734回台灣的路上，跟老師聊大學教育，老師說：「大學是年輕人最有餘裕思考人文問題的人，我們卻要急著將他們往職場推。」對我而言是以正向心態擁抱自己的餘裕，且越發覺得自己念的書太少，要多讀書。Some rights reserved 田野歷史閩東大刀會走私One clap, two clap, three clap, forty?By clapping more or less, you can signal to us which stories really stand out.Yun-Chen Chien（簡韻真）Nobody in @g0v.tw, PM in sense.tw to build online deliberation tools. Caring #civictech #opengov #startup. Now researching on Internet and open democracy.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_content[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "9d75d0f6-b866-4c4e-ba3f-edb1201cdadb",
    "_uuid": "9eb05d3d97036388da1e431683c7272c2c203fec",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 5min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_raw_content = preprocess(path_to_inp_json_file=os.path.join(PATH_TO_DATA, \n",
    "                                                                  'test.json'),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "25fef59c-d54f-411c-a9c7-4a675b29a989",
    "_uuid": "de8308666fe1f7e111edb7ae29a8ec5bafea84dd"
   },
   "source": [
    "We'll use a linear model (`Ridge`) with a very simple feature extractor – `CountVectorizer`, meaning that we resort to the Bag-of-Words approach. For now, we are leaving only 50k features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "39f25d08-a576-4535-8527-d25ddfedebd6",
    "_uuid": "51549a949259a1cc1330d513cbd3c60a8c5a371b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "05342073-facd-4b75-8e94-0f3ad63f79f3",
    "_uuid": "d96e23b597cdbcc1d13f4fa7b2051c4515b1c2b4",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m             \u001b[0mn_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_sort_features\u001b[1;34m(self, X, vocabulary)\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mmap_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mold_val\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'clip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = cv.fit_transform(train_raw_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "370036a0-1b59-46d3-b1d2-ba6f22400e7a",
    "_uuid": "aa5f327814464d01eb6addefd13e510e28a0bb67",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "CountVectorizer - Vocabulary wasn't fitted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vocabulary_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: CountVectorizer - Vocabulary wasn't fitted."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = cv.transform(test_raw_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "873abee7-442d-49df-931e-7e59d0c990b9",
    "_uuid": "fc837f60e80e595839ff1cb0b0e97bb7c8232f17",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1edc748011d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9927589b-52e8-4779-88e9-0d68e06d5233",
    "_uuid": "bb2ce6a072594f15d0e6165f6dc1b95a16f2e282"
   },
   "source": [
    "Read targets from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4110961a-e9c7-49cb-8254-6a8ef3ebaf9d",
    "_uuid": "436102b8f71ce57efbe26a72ea32ae201629f8e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "98d188dc-a207-46a2-a895-739712c778cd",
    "_uuid": "7a4d7f5b14479c2de41641c985a23bd74c468b83",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a7c8da46-715f-4b8b-bbc9-50b158aab78d",
    "_uuid": "5077b30518fea62218c98a3a02b14dcac19112ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "baca6a37-5b08-4a8c-b405-783a1ce13d34",
    "_uuid": "3404a2c96aada745215025eaf04e5c510098d2e8"
   },
   "source": [
    "Make a 30%-holdout set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "819ccd8d-33c3-4714-8dbf-c886c019d2e2",
    "_uuid": "2958f3005056ce5d56911a5edc1d8486eba789a1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part = X_train[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid =  X_train[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "49f43af6-0081-430c-ba4c-ed20e803553b",
    "_uuid": "3be18a01734b95c4ed79d45b8d60b04cd48a74e6"
   },
   "source": [
    "Now we are ready to fit a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14957c67-8989-44ce-b411-051bfe49e2be",
    "_uuid": "49f162fa4c0c775db9cc9491ccc935d992709abe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "af0cf153-869a-44bc-90ab-d502f4d49dec",
    "_uuid": "63a64b164c1c323d9a71dd56beb5c55732a9df00",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "106400fa-4ca2-4eae-966f-0398f2fc3e2a",
    "_uuid": "9dab2f98d5caddda453f80e4d1be835d4c542f8a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ridge.fit(X_train_part, y_train_part);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "81d72242-e201-4a96-9572-6bf816d772ac",
    "_uuid": "95d7bf69d473fa33a5a688d3c22f14d0c1944cb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_pred = ridge.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "27841398-b988-4df1-8d5a-0d439fce7703",
    "_uuid": "21beec2c7186d8f6a93a0cdb3c95838d066292ec"
   },
   "source": [
    "Let's plot predictions and targets for the holdout set. Recall that these are #recommendations (= #claps) of Medium articles with the `np.log1p` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a2487849-80f2-4786-97aa-172ddf2782e5",
    "_uuid": "ae68ecea606621471e7bfed5a68448b43b676e2e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(y_valid, bins=30, alpha=.5, color='red', label='true', range=(0,10));\n",
    "plt.hist(ridge_pred, bins=30, alpha=.5, color='green', label='pred', range=(0,10));\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca0efa6a-ebca-4496-8a2e-0d99f97b2d00",
    "_uuid": "e1a7b075e9cc292e6e9772f5bbfcc90dfb9186b1"
   },
   "source": [
    "As we can see, the prediction is far from perfect, and we get MAE $\\approx$ 1.3 that corresponds to $\\approx$ 2.7 error in #recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58b14c8b-ba67-43b3-bb41-1fd3e1dd6071",
    "_uuid": "651bc8958bd1bd38a1c18c2444648e5e076e2cbf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_mae = mean_absolute_error(y_valid, ridge_pred)\n",
    "valid_mae, np.expm1(valid_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1253943-fcd1-4df9-b740-cf2cf719b8ba",
    "_uuid": "41bf4f23f385fa1f677394828578cf1994d2d0e0"
   },
   "source": [
    "Finally, train the model on the full accessible training set, make predictions for the test set and form a submission file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "03ac15c3-7022-4156-ae35-e9cc38daffd4",
    "_uuid": "c0e28441751c62dd796b029c59dc3c88e6473c6c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ridge.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "84871bdd-9acc-418c-9e14-ba773962fda2",
    "_uuid": "0d6c45e96e16ce82c18d02fec143c0470536792d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ridge_test_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c9a2a2c7-e033-411e-921f-6ea814c0323e",
    "_uuid": "bdf4928c1ef8be25f50d4293849745353e4c5f90",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "    path_to_sample=os.path.join(PATH_TO_DATA, 'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "feda5e9a-09d5-4c11-8c56-29c2e99c1ec2",
    "_uuid": "80583fd5a7aadc53a5fce658404719805908539b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_submission_file(prediction=ridge_test_pred, \n",
    "                      filename='first_ridge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cf4bd078-fc3e-4e16-bdb7-95b40957a012",
    "_uuid": "bdfada7d6b984b1c89c0b68d1b95a135cb93aa2f"
   },
   "source": [
    "With this, you'll get 1.91185 on [public leaderboard](https://www.kaggle.com/c/how-good-is-your-medium-article/leaderboard). This is much higher than our validation MAE. This indicates that the target distribution in test set somewhat differs from that of the training set (recent Medium articles are more popular). This shouldn't confuse us as long as we see a correlation between local improvements and improvements on the leaderboard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "03175b91-3aca-495d-a03d-e81b8b8819da",
    "_uuid": "3a4ec3a8d30a0ac0d5cfe27d911ee742fccecbf2"
   },
   "source": [
    "Some ideas for improvement:\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used `C`=1 as a regularization parameter, this can be changed \n",
    "- SGD and Vowpal Wabbit will learn much faster\n",
    "- In our course, we don't cover neural nets. But it's not obliged to use GRUs or LSTMs in this competition. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
